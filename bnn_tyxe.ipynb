{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c130a0-f6bf-46fa-85ca-6a893b07b90b",
   "metadata": {},
   "source": [
    "# TyXe \n",
    "\n",
    "TyXe (Ancient greek: goddess of chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952c20d5-5238-4e6d-954f-e90170929bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e49bac-1288-4863-a3f6-2798f6b8df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first some imports:\n",
    "\n",
    "import contextlib\n",
    "import functools\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import tyxe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57eb3231-a267-4bf0-b8c0-7c5fb99bf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset helper functions\n",
    "\n",
    "from utils import make_loaders_resnet_cifar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590c455a-c2af-45ff-adbf-ff42f0f89e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- PARAMETERS OF BAYESIAN RESNET TRAINING ------\n",
    "\n",
    "inference: str = \"ml\"\n",
    "architecture: str = \"resnet18\"\n",
    "dataset: str = \"cifar10\" # 10 or 100\n",
    "train_batch_size: int = 10\n",
    "test_batch_size: int = 10\n",
    "local_reparameterization: bool = False # important: variance reduction for gradients!\n",
    "flipout: bool = False\n",
    "num_epochs: int = 1\n",
    "test_samples: int = 20\n",
    "max_guide_scale: float = 0.1 # to prevent underfitting\n",
    "rank: int = 10\n",
    "root: str = os.environ.get(\"DATSETS_PATH\", \"./data\")\n",
    "seed: int = 42\n",
    "output_dir: Optional[str] = None\n",
    "pretrained_weights: Optional[str] = None # path to pretrained weights\n",
    "scale_only: bool = False\n",
    "lr: float = 0.001\n",
    "milestones: Optional[List[int]] = None\n",
    "gamma: float = 0.1\n",
    "mock_dataset: bool = False\n",
    "\n",
    "# ----- check args: inference, architecture, dataset ------\n",
    "inference_options = [\n",
    "    \"ml\",\n",
    "    \"map\",\n",
    "    \"mean-field\",\n",
    "    \"last-layer-mean-field\",\n",
    "    \"last-layer-full\",\n",
    "    \"last-layer-low-rank\"\n",
    "]\n",
    "assert inference in inference_options, inference\n",
    "\n",
    "resnets = [n for n in dir(torchvision.models) if (n.startswith(\"resnet\") or n.startswith(\"wide_resnet\")) and n[-1].isdigit()]\n",
    "assert architecture in resnets, architecture\n",
    "\n",
    "datasets = [\"cifar10\", \"cifar100\", \"mnist\"]\n",
    "assert dataset in datasets, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b9251-3203-48d3-bdc4-fcea99d1dabc",
   "metadata": {},
   "source": [
    "### Initialize our Dataset and Model\n",
    "* arbitrary pytorch datasets and models work\n",
    "* it is straightforward to go integrate TyXe into any existing Pytorch workflow since we just start out with an arbitrary `torch.nn.Module`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49643f8-6565-40ee-82c9-4ff725ea25f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# ----- set up pyro & torch -----\n",
    "pyro.set_rng_seed(seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# ----- set up dataset and model -----\n",
    "def make_net(dataset, architecture):\n",
    "    net = getattr(torchvision.models, architecture)(pretrained=True)\n",
    "    if dataset.startswith(\"cifar\"):\n",
    "        net.conv1 = nn.Conv2d(3, net.conv1.out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        net.maxpool = nn.Identity()\n",
    "        num_classes = 10 if dataset.endswith(\"10\") else 100\n",
    "        net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "    return net\n",
    "\n",
    "train_loader, test_loader, ood_loader = make_loaders(dataset, root, train_batch_size, test_batch_size, use_cuda, mock_dataset)\n",
    "net: torch.nn.Module = make_net(dataset, architecture).to(device)\n",
    "if pretrained_weights is not None:\n",
    "    sd = torch.load(pretrained_weights, map_location=device)\n",
    "    net.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b50830-8337-41ce-b004-50b52d2f6e52",
   "metadata": {},
   "source": [
    "### Set up ResNet to be Bayesian using TyXe\n",
    "\n",
    "To set up a Bayesian Model in TyXe we need to select one of a few options for each of:\n",
    "\n",
    "1. **Likelihood** - The Likelihood of our Training Data $p(D|\\theta)$.\n",
    "2. **Guide** - The Variational Distribution $q(\\theta|D)$. \n",
    "3. **Prior** - Our Prior Belief $p(\\theta)$ about our parameters. Distribution will be around the pretrained weights' values.\n",
    "\n",
    "Our choice for each of these three components does two things:\n",
    "* Determine the family of distributions the particular object may belong to.\n",
    "* Initialize the distribution's parameters.\n",
    "\n",
    "Let's go through the meaning and options for each of the three components, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb5129-a583-4540-bb03-888d60ba2654",
   "metadata": {},
   "source": [
    "#### 1. Setting up the Likelihood\n",
    "\n",
    "The Likelihood of our Training Data $p(D|\\theta)$. The support of the distribution must be equal in size to the number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdd8e8a-675d-43c4-b271-e95d7d18a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli, Categorical, HeteroskedasticGaussian, HomoskedasticGaussian\n",
    "likelihood = tyxe.likelihoods.Categorical(len(train_loader.sampler))\n",
    "\n",
    "# uncomment for documentation:\n",
    "# tyxe.likelihoods.HeteroskedasticGaussian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e13e86-1c4a-407a-88a3-cd99e3855779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f314c4-6d20-4fec-9130-7c46c813f4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e68c8-c17e-494a-bbd1-c577e4e4e1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a73c22c-2a32-4632-83ee-0bb15ac20092",
   "metadata": {},
   "source": [
    "#### 2. Setting up our Guide\n",
    "\n",
    "The choice of the variational distribution is where most of our flexibility lies. \n",
    "It is recommended and most convenient to use one of the `Autoguide`s, either from pyro or TyXe.\n",
    "The TyXe `BNN`s expect an only partially initialized `guide` object\n",
    "Let's go through some of the options:\n",
    "1. Maximum Likelihood: it is straightforward to just do maximum likelihood by letting the guide be `None`.\n",
    "2. Maximum a posteriori inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae64345-f124-4b47-a5fb-86d4fff06e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AutoCallable', 'AutoContinuous', 'AutoDelta', 'AutoDiagonalNormal', 'AutoDiscreteParallel', 'AutoGuide', 'AutoGuideList', 'AutoIAFNormal', 'AutoLaplaceApproximation', 'AutoLowRankMultivariateNormal', 'AutoMultivariateNormal', 'AutoNormal', 'AutoNormalizingFlow']\n"
     ]
    }
   ],
   "source": [
    "if inference == \"ml\":\n",
    "    # do maximum likelihood\n",
    "    test_samples = 1\n",
    "    guide = None\n",
    "elif inference == \"map\":\n",
    "    # maximum a posteriori inference \n",
    "    test_samples = 1\n",
    "    guide = functools.partial(\n",
    "        pyro.infer.autoguide.AutoDelta,\n",
    "        init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net)\n",
    "    )\n",
    "elif inference == \"mean-field\":\n",
    "    guide = functools.partial(\n",
    "        tyxe.guides.AutoNormal,\n",
    "        init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net),\n",
    "        init_scale=1e-4,\n",
    "        max_guide_scale=max_guide_scale, # prevent underfitting\n",
    "        train_loc=not scale_only # train mean parameter?\n",
    "    )\n",
    "elif inference.startswith(\"last-layer\"):\n",
    "    if pretrained_weights is None:\n",
    "        raise ValueError(\"Asked to do last-layer inference, but no pre-trained weights were provided.\")\n",
    "    # turning parameters except for last layer in buffers to avoid training them\n",
    "    # this might be avoidable via poutine.block\n",
    "    for module in net.modules():\n",
    "        if module is not net.fc:\n",
    "            for param_name, param in list(module.named_parameters(recurse=False)):\n",
    "                delattr(module, param_name)\n",
    "                module.register_buffer(param_name, param.detach().data)\n",
    "\n",
    "    if inference == \"last-layer-mean-field\":\n",
    "        guide = functools.partial(\n",
    "            tyxe.guides.AutoNormal, \n",
    "            init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net),\n",
    "            init_scale=1e-4\n",
    "        )\n",
    "    elif inference == \"last-layer-full\":\n",
    "        guide = functools.partial(\n",
    "            pyro.infer.autoguide.AutoMultivariateNormal,\n",
    "            init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net),\n",
    "            init_scale=1e-4\n",
    "        )\n",
    "    elif inference == \"last-layer-low-rank\":\n",
    "        guide = functools.partial(\n",
    "            pyro.infer.autoguide.AutoLowRankMultivariateNormal,\n",
    "            rank=rank,\n",
    "            init_loc_fn=tyxe.guides.PretrainedInitializer.from_net(net),\n",
    "            init_scale=1e-4\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError(f\"Invalid option for inference: '{inference}''\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Invalid option for inference: '{inference}''\")\n",
    "\n",
    "print(\"Automatic Guide Families:\")\n",
    "print([g for g in dir(pyro.infer.autoguide) if g.startswith(\"Auto\")])\n",
    "\n",
    "# uncomment for documentation:\n",
    "# pyro.infer.autoguide.AutoDelta?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09124b-3a23-4914-a79e-e968485a0796",
   "metadata": {},
   "source": [
    "#### 3. Setting up our Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0423d1d9-124f-4869-842c-1bb3598e7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABCMeta', 'DictPrior', 'IIDPrior', 'LambdaPrior', 'LayerwiseNormalPrior', 'Prior', 'PyroParam', 'PyroSample']\n"
     ]
    }
   ],
   "source": [
    "# it is standard practice to not be bayesian about batchnorm modules:\n",
    "prior_kwargs = {\n",
    "    \"expose_all\": False, # do not treat all nn.Modules with pyro \n",
    "    \"hide_module_types\": (nn.BatchNorm2d,) # specifically, ignore batchnorms\n",
    "}\n",
    "\n",
    "# our choice of guide impacts how we need to initialize the Prior:\n",
    "if inference == \"ml\":\n",
    "    # do not be bayesian if we are doing maximum likelihood\n",
    "    prior_kwargs[\"hide_all\"] = True\n",
    "elif inference.startswith(\"last-layer\"):\n",
    "    # only be bayesian about the final, fully connected layer\n",
    "    del prior_kwargs['hide_module_types']\n",
    "    prior_kwargs[\"expose_modules\"] = [net.fc]\n",
    "    \n",
    "prior = tyxe.priors.IIDPrior(\n",
    "    dist.Normal(\n",
    "        torch.zeros(1, device=device),\n",
    "        torch.ones(1, device=device)\n",
    "    ),\n",
    "    **prior_kwargs\n",
    ")\n",
    "\n",
    "# IIDPrior, DictPrior, LambdaPrior, LayerwiseNormalPrior\n",
    "print(\"Available Prior Distributions:\")\n",
    "print([p for p in dir(tyxe.priors) if p[0].upper() == p[0] and not \"_\" in p])\n",
    "\n",
    "# uncomment for documentation:\n",
    "# tyxe.priors.IIDPrior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0558721-fd57-4d79-a8e5-6803da65a41f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "submodule net has executed outside of supermodule",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Finally set up our VariationalBNN!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bnn \u001b[38;5;241m=\u001b[39m \u001b[43mtyxe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariationalBNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/tyxe-0.0.1-py3.8.egg/tyxe/bnn.py:167\u001b[0m, in \u001b[0;36mVariationalBNN.__init__\u001b[0;34m(self, net, prior, likelihood, net_guide_builder, likelihood_guide_builder, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, prior, likelihood, net_guide_builder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, likelihood_guide_builder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_guide_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     weight_sample_sites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(util\u001b[38;5;241m.\u001b[39mpyro_sample_sites(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet))\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m likelihood_guide_builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/tyxe-0.0.1-py3.8.egg/tyxe/bnn.py:124\u001b[0m, in \u001b[0;36m_SupervisedBNN.__init__\u001b[0;34m(self, net, prior, likelihood, net_guide_builder, name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, prior, likelihood, net_guide_builder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_guide_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood \u001b[38;5;241m=\u001b[39m likelihood\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/tyxe-0.0.1-py3.8.egg/tyxe/bnn.py:71\u001b[0m, in \u001b[0;36mGuidedBNN.__init__\u001b[0;34m(self, net, prior, guide_builder, name)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, prior, guide_builder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_guide \u001b[38;5;241m=\u001b[39m guide_builder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet) \u001b[38;5;28;01mif\u001b[39;00m guide_builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _empty_guide\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/tyxe-0.0.1-py3.8.egg/tyxe/bnn.py:43\u001b[0m, in \u001b[0;36m_BNN.__init__\u001b[0;34m(self, net, prior, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, prior, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m net\n\u001b[1;32m     44\u001b[0m     pynn\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mto_pyro_module_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior \u001b[38;5;241m=\u001b[39m prior\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/pyro_ppl-1.4.0-py3.8.egg/pyro/nn/module.py:484\u001b[0m, in \u001b[0;36mPyroModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, PyroParam):\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# Create a new PyroParam, overwriting any old value.\u001b[39;00m\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/pyro_ppl-1.4.0-py3.8.egg/pyro/nn/module.py:380\u001b[0m, in \u001b[0;36mPyroModule.add_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03mAdds a child module to the current module.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, PyroModule):\n\u001b[0;32m--> 380\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pyro_set_supermodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_make_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pyro_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pyro_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39madd_module(name, module)\n",
      "File \u001b[0;32m~/fun/quant/hacking-nn/bnn/bayes/lib/python3.8/site-packages/pyro_ppl-1.4.0-py3.8.egg/pyro/nn/module.py:403\u001b[0m, in \u001b[0;36mPyroModule._pyro_set_supermodule\u001b[0;34m(self, name, context)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, PyroModule):\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39m_pyro_context\u001b[38;5;241m.\u001b[39mused, \\\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmodule \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has executed outside of supermodule\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m    405\u001b[0m         value\u001b[38;5;241m.\u001b[39m_pyro_set_supermodule(_make_name(name, key), context)\n",
      "\u001b[0;31mAssertionError\u001b[0m: submodule net has executed outside of supermodule"
     ]
    }
   ],
   "source": [
    "# Finally set up our VariationalBNN!\n",
    "bnn = tyxe.VariationalBNN(\n",
    "    net, prior, likelihood, guide\n",
    ")\n",
    "\n",
    "# uncomment for documentation:\n",
    "# bnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8164242-7504-4e92-aa72-a25c469074f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient variance reduction techniques:\n",
    "if local_reparameterization:\n",
    "    if flipout:\n",
    "        raise RuntimeError(\"Can't use both local reparameterization and flipout, pick one.\")\n",
    "    train_context = tyxe.poutine.local_reparameterization\n",
    "elif flipout:\n",
    "    train_context = tyxe.poutine.flipout\n",
    "else:\n",
    "    train_context = contextlib.nullcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17ce83dd-9253-4982-8ec5-13491f6f8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASGD', 'Adadelta', 'Adagrad', 'AdagradRMSProp', 'Adam', 'AdamW', 'Adamax', 'ChainedScheduler', 'ClippedAdam', 'ConstantLR', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'CyclicLR', 'DCTAdam', 'ExponentialLR', 'LambdaLR', 'LinearLR', 'MultiStepLR', 'MultiplicativeLR', 'NAdam', 'OneCycleLR', 'PyroLRScheduler', 'PyroOptim', 'RAdam', 'RMSprop', 'ReduceLROnPlateau', 'Rprop', 'SGD', 'SequentialLR', 'SparseAdam', 'StepLR']\n"
     ]
    }
   ],
   "source": [
    "# pyro-specific: optimizer must come from pyro.optim\n",
    "if milestones is None:\n",
    "    optim = pyro.optim.Adam({\"lr\": lr})\n",
    "else:\n",
    "    optimizer = torch.optim.Adam\n",
    "    optim = pyro.optim.MultiStepLR({\"optimizer\": optimizer, \"optim_args\": {\"lr\": lr}, \"milestones\": milestones, \"gamma\": gamma})\n",
    "\n",
    "print(\"All typical optimizers & schedulers are supported by pyro.optim:\")\n",
    "print([opt for opt in dir(pyro.optim) if \"_\" not in opt and opt[0] == opt[0].upper()])\n",
    "    \n",
    "# tyXe-specific: evaluation and logging may be done using a callback function, passed to the bnn.fit() method\n",
    "# callback is called after every epoch with the following arguments:\n",
    "def callback(\n",
    "        b: tyxe.VariationalBNN, # bnn\n",
    "        i: int, # epoch number\n",
    "        avg_elbo: float # mean elbo this epoch\n",
    "    ):\n",
    "    avg_err, avg_ll = 0., 0.\n",
    "    for x, y in iter(test_loader):\n",
    "        err, ll = b.evaluate(x.to(device), y.to(device), num_predictions=test_samples)\n",
    "        avg_err += err / len(test_loader.sampler)\n",
    "        avg_ll += ll / len(test_loader.sampler)\n",
    "    print(f\"ELBO={avg_elbo}; test error={100 * avg_err:.2f}%; LL={avg_ll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11d17e-a4c5-443e-a9a9-c425cab783b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d071f11-1f68-4123-82fa-7bd21b05b8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO=61353.20252763672; test error=28.20%; LL=-0.8372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------ TRAIN THE MODEL ------\n",
    "with train_context():\n",
    "    bnn.fit(train_loader, optim, num_epochs, callback=callback, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a3c9f-080d-4b57-a871-9713e2c840a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally store results by simply using torch.save:\n",
    "if output_dir is not None:\n",
    "    pyro.get_param_store().save(os.path.join(output_dir, \"param_store.pt\"))\n",
    "    torch.save(bnn.state_dict(), os.path.join(output_dir, \"state_dict.pt\"))\n",
    "\n",
    "    test_predictions = torch.cat([bnn.predict(x.to(device), num_predictions=test_samples)\n",
    "                                  for x, _ in iter(test_loader)])\n",
    "    torch.save(test_predictions.detach().cpu(), os.path.join(output_dir, \"test_predictions.pt\"))\n",
    "\n",
    "    ood_predictions = torch.cat([bnn.predict(x.to(device), num_predictions=test_samples)\n",
    "                                 for x, _ in iter(ood_loader)])\n",
    "    torch.save(ood_predictions.detach().cpu(), os.path.join(output_dir, \"ood_predictions.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681240e-c8b6-4b91-a8ef-50009a03ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
